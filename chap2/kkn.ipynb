{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify0(inx, dataset, labels, K=5):\n",
    "    \"\"\"K-Nearest Neighbors algorithm\n",
    "\n",
    "    :param inx: input data .e.g [123, 34, 314]\n",
    "    :param dataset: dataset (panda matrix) e.g.\n",
    "            [ [123,1123,412], [123, 1665, 546], ......, [675,345,8676]\n",
    "    :param labels: labeled vector corresponding to each row of dataset (panda matrix) e.g.\n",
    "            [ \"largeDoses\", \"smallDoses\", \"didntLike\", ...... , \"didntLike\"]\n",
    "    :param K: number if nearest neighbor (+ve integer)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_size = dataset.shape[0]  # no of rows\n",
    "\n",
    "    # make a matrix of same size of dataset to find difference of input and each and every dataset\n",
    "    inx_matrix = pd.np.tile(inx, (dataset_size, 1))  # tile(vector, (row_len, column_len))\n",
    "\n",
    "    diff_matrix = inx_matrix - dataset\n",
    "    square_diff_matrix = diff_matrix ** 2\n",
    "    square_distance = square_diff_matrix.sum(axis=1)\n",
    "    distance = square_distance ** 0.5\n",
    "\n",
    "    sorted_distance_indicies = distance.argsort()\n",
    "\n",
    "    class_count = {}\n",
    "    for i in range(K):\n",
    "        vote_label = labels.iloc[sorted_distance_indicies.iloc[i]]\n",
    "        class_count[vote_label] = class_count.get(vote_label, 0) + 1\n",
    "\n",
    "    # short dictionary `class_count` in decreasing order by its value (high vote to low vote)\n",
    "    sorted_class_count = sorted(class_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    winner_class = sorted_class_count[0][0]\n",
    "    return winner_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file2matrix(filename):\n",
    "    \"\"\"\n",
    "    parse dataset text file and return dataset and label vector\n",
    "    :param filename: local filepath or web address to file\n",
    "    :return: dataset, labels\n",
    "    \"\"\"\n",
    "    header_names = [\"frequentFlyerMiles\", \"VideoGamePlayedHour\", \"IceCreamEatenLiter\", \"labels\"]\n",
    "    dataset = pd.read_csv(filename, sep='\\t', names=header_names)  # provided sample is tab separated\n",
    "\n",
    "    features_matrix = dataset.loc[:, : \"IceCreamEatenLiter\"]\n",
    "    label_vector = dataset.loc[:, \"labels\"]\n",
    "\n",
    "    return features_matrix, label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_norm(dataset):\n",
    "    \"\"\"\n",
    "    Automatically normalize dataset to value between 0 and 1\n",
    "    :param dataset: panda dataframe or numpy array\n",
    "    :return: (normalized_dataset, ranges, min_values)\n",
    "    \"\"\"\n",
    "    min_values = dataset.min()\n",
    "    max_values = dataset.max()\n",
    "    ranges = max_values - min_values\n",
    "    m = dataset.shape[0]\n",
    "    normalized_dataset = dataset - pd.np.tile(min_values, (m, 1))\n",
    "    normalized_dataset = normalized_dataset / pd.np.tile(ranges, (m, 1))\n",
    "    return normalized_dataset, ranges, min_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dating_class_test():\n",
    "    ho_ratio = 0.10\n",
    "    dating_data_matrix, dating_labels = file2matrix('datingTestSet2')\n",
    "    normalized_matrix, ranges, min_values = auto_norm(dating_data_matrix)\n",
    "    m = normalized_matrix.shape[0]\n",
    "    num_test_vecs = int(m * ho_ratio)\n",
    "    error_count = 0.0\n",
    "\n",
    "    for i in range(num_test_vecs):\n",
    "        classifier_result = classify0(\n",
    "            normalized_matrix.loc[i, :],\n",
    "            normalized_matrix.loc[num_test_vecs:m, :],\n",
    "            dating_labels.loc[num_test_vecs:m], 3\n",
    "        )\n",
    "        print(f\"Result: {classifier_result}, Expected: {dating_labels[i]}\")\n",
    "        if classifier_result != dating_labels[i]:\n",
    "            error_count += 1.0\n",
    "    print(f\"Total error rate is {error_count/float(num_test_vecs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 2, Expected: 2\n",
      "Result: 1, Expected: 1\n",
      "Result: 1, Expected: 1\n",
      "Result: 1, Expected: 1\n",
      "Result: 1, Expected: 1\n",
      "Result: 3, Expected: 3\n",
      "Result: 3, Expected: 3\n",
      "Result: 1, Expected: 1\n",
      "Result: 3, Expected: 3\n",
      "Result: 1, Expected: 1\n",
      "Result: 1, Expected: 1\n",
      "Result: 2, Expected: 2\n",
      "Result: 1, Expected: 1\n",
      "Result: 1, Expected: 1\n",
      "Result: 1, Expected: 1\n",
      "Result: 1, Expected: 1\n",
      "Result: 1, Expected: 1\n",
      "Result: 2, Expected: 2\n",
      "Result: 3, Expected: 3\n",
      "Result: 2, Expected: 2\n",
      "Result: 1, Expected: 1\n",
      "Result: 3, Expected: 2\n",
      "Result: 3, Expected: 3\n",
      "Result: 2, Expected: 2\n",
      "Result: 3, Expected: 3\n",
      "Result: 2, Expected: 2\n",
      "Result: 3, Expected: 3\n",
      "Result: 2, Expected: 2\n",
      "Result: 1, Expected: 1\n",
      "Result: 3, Expected: 3\n",
      "Result: 1, Expected: 1\n",
      "Result: 3, Expected: 3\n",
      "Result: 1, Expected: 1\n",
      "Result: 2, Expected: 2\n",
      "Result: 1, Expected: 1\n",
      "Result: 1, Expected: 1\n",
      "Result: 2, Expected: 2\n",
      "Result: 3, Expected: 3\n",
      "Result: 3, Expected: 3\n",
      "Result: 1, Expected: 1\n",
      "Result: 2, Expected: 2\n",
      "Result: 3, Expected: 3\n",
      "Result: 3, Expected: 3\n",
      "Result: 3, Expected: 3\n",
      "Result: 1, Expected: 1\n",
      "Result: 1, Expected: 1\n",
      "Result: 1, Expected: 1\n",
      "Result: 1, Expected: 1\n",
      "Result: 2, Expected: 2\n",
      "Result: 2, Expected: 2\n",
      "Result: 1, Expected: 1\n",
      "Result: 3, Expected: 3\n",
      "Result: 2, Expected: 2\n",
      "Result: 2, Expected: 2\n",
      "Result: 2, Expected: 2\n",
      "Result: 2, Expected: 2\n",
      "Result: 3, Expected: 3\n",
      "Result: 1, Expected: 1\n",
      "Result: 2, Expected: 2\n",
      "Result: 1, Expected: 1\n",
      "Result: 2, Expected: 2\n",
      "Result: 2, Expected: 2\n",
      "Result: 2, Expected: 2\n",
      "Result: 2, Expected: 2\n",
      "Result: 2, Expected: 2\n",
      "Result: 3, Expected: 3\n",
      "Result: 2, Expected: 2\n",
      "Result: 3, Expected: 3\n",
      "Result: 1, Expected: 1\n",
      "Result: 2, Expected: 2\n",
      "Result: 3, Expected: 3\n",
      "Result: 2, Expected: 2\n",
      "Result: 2, Expected: 2\n",
      "Result: 3, Expected: 1\n",
      "Result: 3, Expected: 3\n",
      "Result: 1, Expected: 1\n",
      "Result: 1, Expected: 1\n",
      "Result: 3, Expected: 3\n",
      "Result: 3, Expected: 3\n",
      "Result: 1, Expected: 1\n",
      "Result: 2, Expected: 2\n",
      "Result: 3, Expected: 3\n",
      "Result: 3, Expected: 1\n",
      "Result: 3, Expected: 3\n",
      "Result: 1, Expected: 1\n",
      "Result: 2, Expected: 2\n",
      "Result: 2, Expected: 2\n",
      "Result: 1, Expected: 1\n",
      "Result: 1, Expected: 1\n",
      "Result: 3, Expected: 3\n",
      "Result: 2, Expected: 3\n",
      "Result: 1, Expected: 1\n",
      "Result: 2, Expected: 2\n",
      "Result: 1, Expected: 1\n",
      "Result: 3, Expected: 3\n",
      "Result: 3, Expected: 3\n",
      "Result: 2, Expected: 2\n",
      "Result: 1, Expected: 1\n",
      "Result: 3, Expected: 1\n",
      "Total error rate is 0.050505050505050504\n"
     ]
    }
   ],
   "source": [
    "dating_class_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_person():\n",
    "    game_percentage = float(input(\"Percentage of time spending playing video game?\"))\n",
    "    ffmiles = float(input(\"Frequent flyer mile earned per year?\"))\n",
    "    icecream = float(input(\"Liters of ice cream consumed per year?\"))\n",
    "    dating_marix, dating_label = file2matrix('datingTestSet')\n",
    "    normalized_matrix, ranged, min_values = auto_norm(dating_marix)\n",
    "\n",
    "    input_array = pd.np.array([ffmiles, game_percentage, icecream])\n",
    "\n",
    "    classifier_result = classify0(input_array, normalized_matrix, dating_label)\n",
    "    print(f\"Result: {classifier_result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: didntLike\n"
     ]
    }
   ],
   "source": [
    "classify_person()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
